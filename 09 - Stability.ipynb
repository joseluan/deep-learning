{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23187b6",
   "metadata": {},
   "source": [
    "# Estabilidade\n",
    "\n",
    "Neste notebook vamos estudar técnicas que tornam o treinamento de redes neurais mais **estável** e eficiente.  \n",
    "O objetivo é entender como escolhas de **normalização, inicialização de parâmetros, dropout e ajuste dinâmico da taxa de aprendizado** afetam a convergência e o desempenho do modelo.\n",
    "\n",
    "Pontos que abordaremos:\n",
    "\n",
    "- **Normalização de entradas e ativações internas**  \n",
    "- **Batch Normalization**  \n",
    "- **Inicialização de parâmetros (Xavier, He, etc.)**  \n",
    "- **Schedulers de Learning Rate**  \n",
    "\n",
    "Esses elementos ajudam a evitar problemas clássicos como **gradientes explosivos/vanishing**, **treinamento instável** e **convergência lenta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74074b34",
   "metadata": {},
   "source": [
    "## Normalização\n",
    "\n",
    "A normalização é uma técnica fundamental em redes neurais para acelerar e estabilizar o treinamento. A ideia é controlar a escala e a distribuição dos dados, seja na entrada da rede ou entre camadas, reduzindo problemas de gradientes desbalanceados e acelerando a convergência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843e7c1",
   "metadata": {},
   "source": [
    "### Input Normalization\n",
    "\n",
    "Antes do treinamento, normalizamos os dados de entrada $x$ para que apresentem **média próxima de zero** e **desvio padrão próximo de um**:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "- $\\mu$: média global do dataset  \n",
    "- $\\sigma$: desvio padrão global  \n",
    "\n",
    "Isso garante que todas as features estejam em escalas comparáveis.  \n",
    "Vamos calcular $\\mu$ e $\\sigma$ para o dataset **MNIST**, que contém imagens em tons de cinza de dígitos manuscritos, e em seguida podemos aplicar a normalização diretamente durante o carregamento dos dados usando `transforms.Normalize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Carregar dataset apenas como Tensor\n",
    "dataset_tmp = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Concatenar todos os dados em um tensor [N,1,28,28]\n",
    "loader_tmp = torch.utils.data.DataLoader(dataset_tmp, batch_size=len(dataset_tmp), shuffle=False)\n",
    "data_tmp = next(iter(loader_tmp))[0]  # só imagens\n",
    "print(\"Shape:\", data_tmp.shape)   # [60000, 1, 28, 28]\n",
    "\n",
    "# Calcular mean e std por canal\n",
    "mean = data_tmp.mean().item()\n",
    "std = data_tmp.std().item()\n",
    "print(f\"Mean: {mean:.4f}, Std: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Transformação\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_data = torchvision.datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "test_data  = torchvision.datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Subsets menores\n",
    "train_subset = Subset(train_data, torch.randperm(len(train_data))[:3000])\n",
    "val_subset   = Subset(test_data,  torch.randperm(len(test_data))[:1000])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_subset, batch_size=64)\n",
    "\n",
    "print(len(train_subset), len(val_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5ab53",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "\n",
    "Mesmo após normalizar a entrada, as ativações internas podem mudar de escala durante o treinamento, fenômeno conhecido como **internal covariate shift**.  \n",
    "\n",
    "A **Batch Normalization** resolve esse problema ao normalizar as ativações em cada mini-batch:\n",
    "\n",
    "$$\n",
    "\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}, \\quad \n",
    "y_i = \\gamma \\hat{x}_i + \\beta\n",
    "$$\n",
    "\n",
    "- $\\mu_B, \\sigma_B^2$: média e variância do mini-batch  \n",
    "- $\\epsilon$: termo de estabilidade numérica  \n",
    "- $\\gamma, \\beta$: parâmetros treináveis que permitem restaurar escala e deslocamento  \n",
    "\n",
    "Com isso, o treinamento torna-se mais estável, permite taxas de aprendizado maiores e pode acelerar a convergência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso de Batch Normalization para vetores de dimensão 128\n",
    "batch_norm = nn.BatchNorm1d(128)\n",
    "\n",
    "# Batch fictício com 32 amostras de dimensão 128\n",
    "x = torch.randn(32, 128)\n",
    "\n",
    "# Aplicar BatchNorm\n",
    "y = batch_norm(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9d25a",
   "metadata": {},
   "source": [
    "## Inicialização de Parâmetros\n",
    "\n",
    "A escolha da inicialização dos pesos influencia diretamente a propagação dos sinais pela rede e a velocidade de convergência do treinamento.  \n",
    "Se os pesos começarem com valores muito grandes, os gradientes podem explodir; se forem muito pequenos, os gradientes podem desaparecer.  \n",
    "\n",
    "O objetivo das estratégias modernas de inicialização é manter a **variância dos sinais e dos gradientes estável** através das camadas da rede.\n",
    "\n",
    "### Inicializações Simples\n",
    "\n",
    "- **Zeros**: todos os pesos inicializados como zero. Não é recomendada, pois elimina a simetria entre neurônios, impedindo o aprendizado.  \n",
    "- **Uniforme Aleatória**: pesos amostrados de uma distribuição uniforme $U(a,b)$. Pode funcionar em redes rasas, mas em redes profundas tende a causar instabilidade de gradientes.  \n",
    "\n",
    "### Xavier Initialization\n",
    "\n",
    "Proposta por Glorot & Bengio (2010), a ideia é ajustar a variância dos pesos para manter o mesmo nível de variância entre a entrada e a saída de cada camada linear.  \n",
    "\n",
    "$$\n",
    "Var[w] = \\frac{2}{n_{in} + n_{out}}\n",
    "$$\n",
    "\n",
    "- $n_{in}$: número de entradas da camada  \n",
    "- $n_{out}$: número de saídas da camada  \n",
    "\n",
    "Com isso, evita-se tanto a saturação das ativações quanto a explosão/decadência dos gradientes em redes profundas.\n",
    "\n",
    "### He Initialization\n",
    "\n",
    "Proposta por He et al. (2015), é uma variação da Xavier específica para funções de ativação ReLU e suas variantes.  \n",
    "A ideia é considerar que metade das ativações da ReLU são zeradas, exigindo maior variância inicial:  \n",
    "\n",
    "$$\n",
    "Var[w] = \\frac{2}{n_{in}}\n",
    "$$\n",
    "\n",
    "- $n_{in}$: número de entradas da camada  \n",
    "\n",
    "Essa inicialização é o padrão em muitas arquiteturas modernas com ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight_distribution(model, bins=50, title=\"\"):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, m in enumerate(model):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            weights = m.weight.detach().cpu().numpy().flatten()\n",
    "            plt.hist(weights, bins=bins, alpha=0.5, label=f'Layer {i} ({m.out_features} units)')\n",
    "    plt.title(f\"Distribuição dos Pesos - {title}\")\n",
    "    plt.xlabel(\"Valor do Peso\")\n",
    "    plt.ylabel(\"Frequência\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9514b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "# Exemplo de inicialização em um modelo com várias camadas\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização zero\n",
    "for layer in model:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        init.zeros_(layer.weight)\n",
    "        init.zeros_(layer.bias)\n",
    "\n",
    "plot_weight_distribution(model, title=\"Zero Initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização uniforme\n",
    "for layer in model:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        init.uniform_(layer.weight, a=-0.1, b=0.1)\n",
    "        init.zeros_(layer.bias)\n",
    "\n",
    "plot_weight_distribution(model, title=\"Uniform Initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c29e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização normal\n",
    "for layer in model:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        init.normal_(layer.weight, mean=0.0, std=0.05)\n",
    "        init.zeros_(layer.bias)\n",
    "\n",
    "plot_weight_distribution(model, title=\"Normal Initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização He\n",
    "for layer in model:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        init.kaiming_normal_(layer.weight, nonlinearity=\"relu\")\n",
    "        init.zeros_(layer.bias)\n",
    "\n",
    "plot_weight_distribution(model, title=\"He Initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização Xavier\n",
    "for layer in model:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        init.xavier_uniform_(layer.weight)\n",
    "        init.zeros_(layer.bias)\n",
    "\n",
    "plot_weight_distribution(model, title=\"Xavier Initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77174361",
   "metadata": {},
   "source": [
    "## Decaimento da Taxa de Aprendizado\n",
    "\n",
    "A **taxa de aprendizado** ($\\eta$) controla o tamanho dos passos do otimizador.  \n",
    "Se $\\eta$ for muito alta, o treinamento pode divergir; se for muito baixa, pode ser lento.  \n",
    "Uma estratégia comum é aplicar **decaimento da taxa de aprendizado**, ajustando gradualmente $\\eta$ ao longo do treinamento:\n",
    "\n",
    "- **Step Decay**: reduz $\\eta$ em etapas fixas, após um número pré-definido de épocas  \n",
    "\n",
    "$$\n",
    "\\eta_t = \\eta_0 \\cdot \\gamma^{\\lfloor t / s \\rfloor}\n",
    "$$\n",
    "\n",
    "- **Exponential Decay**: reduz $\\eta$ de forma suave e contínua  \n",
    "\n",
    "$$\n",
    "\\eta_t = \\eta_0 \\cdot \\gamma^t\n",
    "$$\n",
    "\n",
    "- **Reduce on Plateau**: monitora uma métrica (ex.: loss de validação) e reduz $\\eta$ quando não há melhora por certo número de épocas  \n",
    "\n",
    "$$\n",
    "\\eta_{t+1} = \\eta_t \\cdot \\gamma \\quad \\text{se não houver melhora por $p$ épocas}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, ReduceLROnPlateau\n",
    "\n",
    "# Modelo simples\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10)\n",
    ").to(device)\n",
    "\n",
    "# Otimizador e scheduler\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, threshold=0.5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Treinamento simples em MNIST\n",
    "n_epochs = 15\n",
    "train_losses = []\n",
    "lrs = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    lrs.append(optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss = {epoch_loss:.4f}, LR = {lrs[-1]:.5f}\")\n",
    "\n",
    "# Plot Loss e LR\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\", color=\"blue\")\n",
    "ax1.plot(range(1, n_epochs+1), train_losses, marker=\"o\", color=\"blue\", label=\"Train Loss\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Learning Rate\", color=\"red\")\n",
    "ax2.plot(range(1, n_epochs+1), lrs, marker=\"s\", linestyle=\"--\", color=\"red\", label=\"LR\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0d677",
   "metadata": {},
   "source": [
    "## Otimizadores\n",
    "\n",
    "Os algoritmos de otimização são essenciais para treinar redes neurais. Eles buscam **minimizar a função de custo** $L(\\theta)$ ajustando os parâmetros $\\theta$ do modelo de forma iterativa.\n",
    "\n",
    "### Gradiente Descendente Básico\n",
    "Fornece um passo uniforme em todas as direções, sem considerar a escala ou correlação entre dimensões, o que pode gerar trajetórias lentas em funções mal condicionadas. O algoritmo atualiza os parâmetros na direção oposta ao gradiente:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\nabla L(\\theta_t)$$\n",
    "\n",
    "- $\\theta_t$: parâmetros atuais do modelo  \n",
    "- $\\eta$: taxa de aprendizado (tamanho do passo)  \n",
    "- $\\nabla L(\\theta_t)$: gradiente da função de custo em relação aos parâmetros  \n",
    "\n",
    "### Momentum\n",
    "Reduz oscilações em direções de alta curvatura e acelera a convergência em vales alongados, aproximando-se de um método de aceleração de gradiente. Ele adiciona uma memória das atualizações anteriores:\n",
    "\n",
    "$$v_{t+1} = \\beta v_t + \\nabla L(\\theta_t)$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta v_{t+1}$$\n",
    "\n",
    "- $v_t$: vetor de \"velocidade\" acumulada  \n",
    "- $\\beta$: coeficiente de momentum (0.9 é comum)  \n",
    "- $\\eta$: taxa de aprendizado  \n",
    "\n",
    "### AdaGrad\n",
    "Normaliza o passo por dimensão, aumentando estabilidade em problemas esparsos, mas a acumulação crescente de $G_t$ tende a reduzir excessivamente a taxa de aprendizado ao longo do tempo. Sua atualização é dada por:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\nabla L(\\theta_t)$$\n",
    "\n",
    "- $G_t$: soma acumulada dos quadrados dos gradientes  \n",
    "- $\\epsilon$: pequeno valor para estabilidade numérica  \n",
    "- $\\eta$: taxa de aprendizado inicial  \n",
    "\n",
    "### RMSprop\n",
    "Evita a saturação do AdaGrad ao introduzir esquecimento exponencial, permitindo adaptação contínua da taxa de aprendizado em problemas não estacionários. A regra de atualização é:\n",
    "\n",
    "$$v_t = \\beta v_{t-1} + (1-\\beta)(\\nabla L(\\theta_t))^2$$\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{v_t + \\epsilon}} \\nabla L(\\theta_t)$$\n",
    "\n",
    "- $v_t$: média móvel dos gradientes ao quadrado  \n",
    "- $\\beta$: fator de decaimento (tipicamente 0.9)  \n",
    "- $\\epsilon$: termo de estabilidade  \n",
    "- $\\eta$: taxa de aprendizado  \n",
    "\n",
    "### Adam\n",
    "Fornece estimativas corrigidas de primeira e segunda ordem, resultando em passos adaptativos que combinam aceleração e escalonamento por dimensão, o que o torna robusto em larga escala e em arquiteturas profundas. O procedimento é:\n",
    "\n",
    "$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1)\\nabla L(\\theta_t)$$\n",
    "$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2)(\\nabla L(\\theta_t))^2$$\n",
    "\n",
    "Correções de viés (necessárias pois $m_t$ e $v_t$ tendem a começar enviesados para baixo no início):\n",
    "\n",
    "$$\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t} \\quad , \\quad \\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}$$\n",
    "\n",
    "Atualização final dos parâmetros:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon}\\,\\hat{m}_t$$\n",
    "\n",
    "- $m_t$: estimativa de primeira ordem (média móvel dos gradientes)  \n",
    "- $v_t$: estimativa de segunda ordem (média móvel dos gradientes ao quadrado)  \n",
    "- $\\hat{m}_t, \\hat{v}_t$: versões corrigidas de viés  \n",
    "- $\\beta_1$: fator de decaimento para $m_t$ (ex: 0.9)  \n",
    "- $\\beta_2$: fator de decaimento para $v_t$ (ex: 0.999)  \n",
    "- $\\epsilon$: termo de estabilidade numérica  \n",
    "- $\\eta$: taxa de aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db6861",
   "metadata": {},
   "source": [
    "### Função de Himmelblau\n",
    "\n",
    "Para analisar e comparar diferentes otimizadores, utilizamos a **função de Himmelblau**, uma função clássica em otimização não convexa. Ela é definida como:\n",
    "\n",
    "$$\n",
    "f(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2\n",
    "$$\n",
    "\n",
    "- Possui **quatro mínimos locais**, sendo todos também mínimos globais, além de pontos de sela.  \n",
    "- É frequentemente usada como benchmark porque apresenta um relevo complexo, que desafia os algoritmos de otimização.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def himmelblau_np(x, y):\n",
    "    return (x**2 + y - 11)**2 + (x + y**2 - 7)**2\n",
    "\n",
    "# Grid\n",
    "X = np.linspace(-6, 6, 200)\n",
    "Y = np.linspace(-6, 6, 200)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = himmelblau_np(X, Y)\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=Z, x=X, y=Y, colorscale=\"viridis\")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Himmelblau's Function\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"x1\",\n",
    "        yaxis_title=\"x2\",\n",
    "        zaxis_title=\"f(x1, x2)\"\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea0133",
   "metadata": {},
   "source": [
    "### Otimização em Funções Não Convexas\n",
    "\n",
    "Considere uma função objetivo $f: \\mathbb{R}^2 \\to \\mathbb{R}$ como a função de Himmelblau:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2\n",
    "$$\n",
    "\n",
    "Esse tipo de função apresenta múltiplos mínimos locais e pontos de sela, o que a torna um bom cenário para comparar otimizadores.\n",
    "\n",
    "O problema geral de otimização pode ser formulado como:\n",
    "\n",
    "$$\n",
    "\\min_{x \\in \\mathbb{R}^n} f(x)\n",
    "$$\n",
    "\n",
    "onde $x = (x_1, x_2, \\dots, x_n)$ são os parâmetros que queremos ajustar.\n",
    "\n",
    "Durante o processo iterativo, mantemos uma sequência de pontos $\\{x_t\\}$, atualizados de acordo com uma regra específica definida por cada otimizador. Em geral:\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t - \\Delta_t\n",
    "$$\n",
    "\n",
    "- $x_t$: vetor de parâmetros na iteração $t$  \n",
    "- $\\Delta_t$: passo de atualização definido pelo algoritmo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5650e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def himmelblau(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    return (x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2\n",
    "\n",
    "def plot_progress(track, losses, func, title=\"\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12, 5))\n",
    "    \n",
    "    # Contours of the function\n",
    "    X = np.linspace(-6, 6, 400)\n",
    "    Y = np.linspace(-6, 6, 400)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = (X**2 + Y - 11)**2 + (X + Y**2 - 7)**2\n",
    "    ax1.contour(X, Y, Z, levels=np.logspace(0, 5, 35), cmap='viridis')\n",
    "\n",
    "    track = torch.stack(track).t()\n",
    "    ax1.plot(track[0,:], track[1,:], marker='o', color=\"red\")\n",
    "    ax1.scatter(track[0,0], track[1,0], color='yellow', marker='*', s=200, label=\"start\")\n",
    "    ax1.set_title(f'progress of x ({title})')\n",
    "    ax1.set_xlim(-6, 6)\n",
    "    ax1.set_ylim(-6, 6)\n",
    "    ax1.set_xlabel(\"x1\")\n",
    "    ax1.set_ylabel(\"x2\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Loss curve\n",
    "    ax2.set_title(f'progress of f(x) ({title})')\n",
    "    ax2.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "    ax2.plot(range(len(losses)), losses, marker='o')\n",
    "    ax2.set_ylabel('objective')\n",
    "    ax2.set_xlabel('iteration')\n",
    "    ax2.set_yscale(\"log\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def run_optimizer(opt_class, opt_params, x_init, steps=50, lr=0.01):\n",
    "    x = x_init.clone().detach().requires_grad_(True)\n",
    "    optimizer = opt_class([x], lr=lr, **opt_params)\n",
    "    track, losses = [], []\n",
    "    for _ in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        loss = himmelblau(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        track.append(x.detach().clone())\n",
    "        losses.append(loss.item())\n",
    "    return track, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff69b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"SGD\": (optim.SGD, {}),\n",
    "    \"SGD+Momentum\": (optim.SGD, {\"momentum\": 0.2}),\n",
    "    \"Adagrad\": (optim.Adagrad, {}),\n",
    "    \"RMSprop\": (optim.RMSprop, {\"alpha\": 0.9}),\n",
    "    \"Adam\": (optim.Adam, {})\n",
    "}\n",
    "\n",
    "x_start = torch.tensor([-4.0, 0.0])  # far from any minimum\n",
    "\n",
    "for name, (opt_class, opt_params) in optimizers.items():\n",
    "    track, losses = run_optimizer(opt_class, opt_params, x_start, steps=100, lr=0.03)\n",
    "    plot_progress(track, losses, himmelblau, title=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b0efa",
   "metadata": {},
   "source": [
    "### Modelo Completo\n",
    "\n",
    "Agora reunimos em um único modelo os principais elementos discutidos e comparamos diferentes otimizadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y60xfmh3otq",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, init_type=\"he\", dropout=0.0):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        self._initialize_weights(init_type)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.layers(x)\n",
    "\n",
    "    def _initialize_weights(self, init_type):\n",
    "        for m in self.layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if init_type == \"he\":\n",
    "                    init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "                    init.zeros_(m.bias)\n",
    "                elif init_type == \"xavier\":\n",
    "                    init.xavier_uniform_(m.weight)\n",
    "                    init.zeros_(m.bias)\n",
    "                elif init_type == \"zeros\":\n",
    "                    init.zeros_(m.weight)\n",
    "                    init.zeros_(m.bias)\n",
    "                elif init_type == \"uniform\":\n",
    "                    init.uniform_(m.weight, a=-0.1, b=0.1)\n",
    "                    init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, epochs=10, device=\"cpu\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---- Treino ----\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "        \n",
    "        history[\"train_loss\"].append(total_loss / len(train_loader))\n",
    "        history[\"train_acc\"].append(100 * correct / total)\n",
    "\n",
    "        # ---- Validação ----\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        history[\"val_loss\"].append(val_loss / len(val_loader))\n",
    "        history[\"val_acc\"].append(100 * correct / total)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {history['train_loss'][-1]:.4f}, \"\n",
    "              f\"Train Acc: {history['train_acc'][-1]:.2f}% | \"\n",
    "              f\"Val Loss: {history['val_loss'][-1]:.4f}, \"\n",
    "              f\"Val Acc: {history['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_config = {\n",
    "    'SGD': {'lr': 0.01},\n",
    "    'SGD+Momentum': {'lr': 0.01, 'momentum': 0.9},\n",
    "    'Adagrad': {'lr': 0.01},\n",
    "    'RMSprop': {'lr': 0.01},\n",
    "    'Adam': {'lr': 0.01}\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, config in optimizers_config.items():\n",
    "    print(f\"\\nTreinando com {name}...\")\n",
    "\n",
    "    # novo modelo a cada otimizador\n",
    "    model = SimpleNet(init_type=\"he\", dropout=0.0).to(device)\n",
    "\n",
    "    # instanciar otimizador\n",
    "    optimizer_class = getattr(optim, name.split('+')[0])\n",
    "    optimizer = optimizer_class(model.parameters(), **config)\n",
    "\n",
    "    # treinar e guardar histórico\n",
    "    history = train_model(model, train_loader, val_loader, optimizer, epochs=10, device=device)\n",
    "    results[name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce2628",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "colors = sns.color_palette(\"husl\", len(results))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,1)\n",
    "for i, (name, hist) in enumerate(results.items()):\n",
    "    color = colors[i]\n",
    "    plt.plot(hist[\"train_loss\"], label=f\"{name} Train\", color=color)\n",
    "    plt.plot(hist[\"val_loss\"], linestyle=\"--\", label=f\"{name} Val\", color=color)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,2)\n",
    "for i, (name, hist) in enumerate(results.items()):\n",
    "    color = colors[i]\n",
    "    plt.plot(hist[\"train_acc\"], label=f\"{name} Train\", color=color)\n",
    "    plt.plot(hist[\"val_acc\"], linestyle=\"--\", label=f\"{name} Val\", color=color)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ddf312",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "\n",
    "Neste exercício, você deve aplicar os conceitos vistos em aula:\n",
    "\n",
    "1. Carregue o dataset **Fashion-MNIST** de `torchvision.datasets.FashionMNIST` e aplique **normalização** com `transforms.Normalize`, calculando previamente a média e o desvio padrão.  \n",
    "2. Construa um modelo de rede neural utilizando:  \n",
    "   - **Camadas lineares** intercaladas com **Batch Normalization** e **ReLU**\n",
    "   - **Inicialização He** para os pesos\n",
    "3. Treine o modelo usando o **otimizador Adam**.  \n",
    "4. Utilize o scheduler **ReduceLROnPlateau**, monitorando a loss de validação, para ajustar dinamicamente a taxa de aprendizado.  \n",
    "5. Registre e plote a evolução da loss de treino e validação ao longo das épocas, além da curva da taxa de aprendizado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
